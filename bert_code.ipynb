{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"L1VKNWZ6DNkT"},"outputs":[],"source":["# ライブラリのインストール\n","!pip install transformers==4.18.0 fugashi==1.1.0 ipadic==1.0.0 pytorch-lightning==1.6.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCwbcG5Cb9BP"},"outputs":[],"source":["#8-3\n","import itertools\n","import random\n","import json\n","from tqdm import tqdm\n","import numpy as np\n","import unicodedata\n","import pprint\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from transformers import BertJapaneseTokenizer, BertForTokenClassification\n","import pytorch_lightning as pl\n","\n","#学習済みモデル\n","MODEL_NAME = \"cl-tohoku/bert-base-japanese-whole-word-masking\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jqlQrXEmegzp"},"outputs":[],"source":["class NER_tokenizer(BertJapaneseTokenizer):\n","\n","    def encode_plus_tagged(self, text, entities, max_length):\n","        \"\"\"\n","        文章とそれに含まれる固有表現が与えられた時に、\n","        符号化とラベル列の作成を行う。\n","        \"\"\"\n","        # 固有表現の前後でtextを分割し、それぞれのラベルをつけておく。\n","        entities = sorted(entities, key=lambda x: x['span'][0])\n","        splitted = [] # 分割後の文字列を追加していく\n","        position = 0\n","        for entity in entities:\n","            start = entity['span'][0]\n","            end = entity['span'][1]\n","            label = entity['type_id']\n","            # 固有表現ではないものには0のラベルを付与\n","            splitted.append({'text':text[position:start], 'label':0})\n","            # 固有表現には、固有表現のタイプに対応するIDをラベルとして付与\n","            splitted.append({'text':text[start:end], 'label':label})\n","            position = end\n","        splitted.append({'text': text[position:], 'label':0})\n","        splitted = [ s for s in splitted if s['text'] ] # 長さ0の文字列は除く\n","\n","        # 分割されたそれぞれの文字列をトークン化し、ラベルをつける。\n","        tokens = [] # トークンを追加していく\n","        labels = [] # トークンのラベルを追加していく\n","        for text_splitted in splitted:\n","            text = text_splitted['text']\n","            label = text_splitted['label']\n","            tokens_splitted = self.tokenize(text)\n","            labels_splitted = [label] * len(tokens_splitted)\n","            tokens.extend(tokens_splitted)\n","            labels.extend(labels_splitted)\n","\n","        # 符号化を行いBERTに入力できる形式にする。\n","        input_ids = self.convert_tokens_to_ids(tokens)\n","        encoding = self.prepare_for_model(\n","            input_ids,\n","            max_length=max_length,\n","            padding='max_length',\n","            truncation=True\n","        ) # input_idsをencodingに変換\n","        # 特殊トークン[CLS]、[SEP]のラベルを0にする。\n","        labels = [0] + labels[:max_length-2] + [0]\n","        # 特殊トークン[PAD]のラベルを0にする。\n","        labels = labels + [0]*( max_length - len(labels) )\n","        encoding['labels'] = labels\n","\n","        return encoding\n","\n","    def encode_plus_untagged(\n","        self, text, max_length=None, return_tensors=None\n","    ):\n","        \"\"\"\n","        文章をトークン化し、それぞれのトークンの文章中の位置も特定しておく。\n","        \"\"\"\n","        # 文章のトークン化を行い、\n","        # それぞれのトークンと文章中の文字列を対応づける。\n","        tokens = [] # トークンを追加していく。\n","        tokens_original = [] # トークンに対応する文章中の文字列を追加していく。\n","        words = self.word_tokenizer.tokenize(text) # MeCabで単語に分割\n","        for word in words:\n","            # 単語をサブワードに分割\n","            tokens_word = self.subword_tokenizer.tokenize(word)\n","            tokens.extend(tokens_word)\n","            if tokens_word[0] == '[UNK]': # 未知語への対応\n","                tokens_original.append(word)\n","            else:\n","                tokens_original.extend([\n","                    token.replace('##','') for token in tokens_word\n","                ])\n","\n","        # 各トークンの文章中での位置を調べる。（空白の位置を考慮する）\n","        position = 0\n","        spans = [] # トークンの位置を追加していく。\n","        for token in tokens_original:\n","            l = len(token)\n","            while 1:\n","                if token != text[position:position+l]:\n","                    position += 1\n","                else:\n","                    spans.append([position, position+l])\n","                    position += l\n","                    break\n","\n","        # 符号化を行いBERTに入力できる形式にする。\n","        input_ids = self.convert_tokens_to_ids(tokens)\n","        encoding = self.prepare_for_model(\n","            input_ids,\n","            max_length=max_length,\n","            padding='max_length' if max_length else False,\n","            truncation=True if max_length else False\n","        )\n","        sequence_length = len(encoding['input_ids'])\n","        # 特殊トークン[CLS]に対するダミーのspanを追加。\n","        spans = [[-1, -1]] + spans[:sequence_length-2]\n","        # 特殊トークン[SEP]、[PAD]に対するダミーのspanを追加。\n","        spans = spans + [[-1, -1]] * ( sequence_length - len(spans) )\n","\n","        # 必要に応じてtorch.Tensorにする。\n","        if return_tensors == 'pt':\n","            encoding = { k: torch.tensor([v]) for k, v in encoding.items() }\n","\n","        return encoding, spans\n","\n","    def convert_bert_output_to_entities(self, text, labels, spans):\n","        \"\"\"\n","        文章、ラベル列の予測値、各トークンの位置から固有表現を得る。\n","        \"\"\"\n","        # labels, spansから特殊トークンに対応する部分を取り除く\n","        labels = [label for label, span in zip(labels, spans) if span[0] != -1]\n","        spans = [span for span in spans if span[0] != -1]\n","\n","        # 同じラベルが連続するトークンをまとめて、固有表現を抽出する。\n","        entities = []\n","        for label, group \\\n","            in itertools.groupby(enumerate(labels), key=lambda x: x[1]):\n","\n","            group = list(group)\n","            start = spans[group[0][0]][0]\n","            end = spans[group[-1][0]][1]\n","\n","            if label != 0: # ラベルが0以外ならば、新たな固有表現として追加。\n","                entity = {\n","                    \"name\": text[start:end],\n","                    \"span\": [start, end],\n","                    \"type_id\": label\n","                }\n","                entities.append(entity)\n","\n","        return entities"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNYgKHjzIxdi"},"outputs":[],"source":["#8-14\n","#データロード\n","load_data_name = 'json_name.json'\n","dataset = json.load(open(f'/path/to/{load_data_name}','r'))\n","\n","type_id_dict = {\n","    \"技術語\": 1,\n","}\n","\n","#カテゴリをラベルに、テキストの正規化\n","for sample in dataset:\n","  sample['text'] = unicodedata.normalize('NFKC', sample['text'])\n","  for e in sample[\"entities\"]:\n","    e['type_id'] = type_id_dict[e['type']]\n","    del e['type']\n","\n","#データセットの分割\n","random.seed(314)\n","random.shuffle(dataset)\n","n = len(dataset)\n","n_train = int(n*0.6)\n","n_val = int(n*0.2)\n","dataset_train = dataset[:n_train] #学習用\n","dataset_val = dataset[n_train:n_train+n_val]  #検証用\n","dataset_test = dataset[n_train+n_val:] #テスト用"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1I5avywYLkbG"},"outputs":[],"source":["#8-15\n","def create_dataset(tokenizer, dataset, max_length):\n","  dataset_for_loader = []\n","  for sample in dataset:\n","    text = sample['text']\n","    entities = sample['entities']\n","    encoding = tokenizer.encode_plus_tagged(\n","        text, entities, max_length=max_length\n","    )\n","    encoding = {k: torch.tensor(v) for k, v in encoding.items()}\n","    dataset_for_loader.append(encoding)\n","  return dataset_for_loader\n","\n","tokenizer = NER_tokenizer.from_pretrained(MODEL_NAME)\n","\n","#データセットの作成\n","max_length = 256\n","dataset_train_for_loader = create_dataset(\n","    tokenizer, dataset_train, max_length\n",")\n","dataset_val_for_loader = create_dataset(\n","    tokenizer, dataset_val, max_length\n",")\n","\n","#データローダの作成\n","dataloader_train = DataLoader(\n","    dataset_train_for_loader, batch_size=32, shuffle=True\n",")\n","dataloader_val = DataLoader(dataset_val_for_loader, batch_size=256)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"446u47Os_Arh"},"outputs":[],"source":["# 8-16\n","# PyTorch Lightningのモデル\n","class BertForTokenClassification_pl(pl.LightningModule):\n","\n","    def __init__(self, model_name, num_labels, lr):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.bert_tc = BertForTokenClassification.from_pretrained(\n","            model_name,\n","            num_labels=num_labels\n","        )\n","\n","    def training_step(self, batch, batch_idx):\n","        output = self.bert_tc(**batch)\n","        loss = output.loss\n","        self.log('train_loss', loss)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        output = self.bert_tc(**batch)\n","        val_loss = output.loss\n","        self.log('val_loss', val_loss)\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n","\n","checkpoint = pl.callbacks.ModelCheckpoint(\n","    monitor='val_loss',\n","    mode='min',\n","    save_top_k=1,\n","    save_weights_only=True,\n","    dirpath='model/'\n",")\n","\n","trainer = pl.Trainer(\n","    gpus=1,\n","    max_epochs=5,\n","    callbacks=[checkpoint]\n",")\n","\n","# ファインチューニング\n","model = BertForTokenClassification_pl(\n","    MODEL_NAME, num_labels=2, lr=1e-5\n",")\n","trainer.fit(model, dataloader_train, dataloader_val)\n","best_model_path = checkpoint.best_model_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9OU3oPuxCEWz"},"outputs":[],"source":["# 8-17\n","def predict(text, tokenizer, bert_tc):\n","    \"\"\"\n","    BERTで固有表現抽出を行うための関数。\n","    \"\"\"\n","    # 符号化\n","    encoding, spans = tokenizer.encode_plus_untagged(\n","        text, return_tensors='pt'\n","    )\n","    encoding = { k: v.cuda() for k, v in encoding.items() }\n","\n","    # ラベルの予測値の計算\n","    with torch.no_grad():\n","        output = bert_tc(**encoding)\n","        scores = output.logits\n","        labels_predicted = scores[0].argmax(-1).cpu().numpy().tolist()\n","\n","    # ラベル列を固有表現に変換\n","    entities = tokenizer.convert_bert_output_to_entities(\n","        text, labels_predicted, spans\n","    )\n","\n","    return entities\n","\n","# トークナイザのロード\n","tokenizer = NER_tokenizer.from_pretrained(MODEL_NAME)\n","\n","# ファインチューニングしたモデルをロードし、GPUにのせる。\n","model = BertForTokenClassification_pl.load_from_checkpoint(\n","    best_model_path\n",")\n","bert_tc = model.bert_tc.cuda()\n","\n","# 固有表現抽出\n","# 注：以下ではコードのわかりやすさのために、1データづつ処理しているが、\n","# バッチ化して処理を行った方が処理時間は短い\n","entities_list = [] # 正解の固有表現を追加していく。\n","entities_predicted_list = [] # 抽出された固有表現を追加していく。\n","for sample in tqdm(dataset_test):\n","    text = sample['text']\n","    entities_predicted = predict(text, tokenizer, bert_tc) # BERTで予測\n","    entities_list.append(sample['entities'])\n","    entities_predicted_list.append( entities_predicted )\n","    #print(text)\n","    #print(entities_predicted)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qWfDSvX6ad4x"},"outputs":[],"source":["print(\"# 正解\")\n","print(entities_list[0])\n","print(\"# 抽出\")\n","print(entities_predicted_list[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeZzmNigiDsD"},"outputs":[],"source":["# 8-19\n","def evaluate_model(entities_list, entities_predicted_list, type_id=None):\n","    \"\"\"\n","    正解と予測を比較し、モデルの固有表現抽出の性能を評価する。\n","    type_idがNoneのときは、全ての固有表現のタイプに対して評価する。\n","    type_idが整数を指定すると、その固有表現のタイプのIDに対して評価を行う。\n","    \"\"\"\n","    num_entities = 0 # 固有表現(正解)の個数\n","    num_predictions = 0 # BERTにより予測された固有表現の個数\n","    num_correct = 0 # BERTにより予測のうち正解であった固有表現の数\n","\n","    # それぞれの文章で予測と正解を比較。\n","    # 予測は文章中の位置とタイプIDが一致すれば正解とみなす。\n","    for entities, entities_predicted \\\n","        in zip(entities_list, entities_predicted_list):\n","\n","        if type_id:\n","            entities = [ e for e in entities if e['type_id'] == type_id ]\n","            entities_predicted = [\n","                e for e in entities_predicted if e['type_id'] == type_id\n","            ]\n","\n","        get_span_type = lambda e: (e['span'][0], e['span'][1], e['type_id'])\n","        set_entities = set( get_span_type(e) for e in entities )\n","        set_entities_predicted = \\\n","            set( get_span_type(e) for e in entities_predicted )\n","\n","        num_entities += len(entities)\n","        num_predictions += len(entities_predicted)\n","        num_correct += len( set_entities & set_entities_predicted )\n","\n","    # 指標を計算\n","    precision = num_correct/num_predictions # 適合率\n","    recall = num_correct/num_entities # 再現率\n","    f_value = 2*precision*recall/(precision+recall) # F値\n","\n","    result = {\n","        'num_entities': num_entities,\n","        'num_predictions': num_predictions,\n","        'num_correct': num_correct,\n","        'precision': precision,\n","        'recall': recall,\n","        'f_value': f_value\n","    }\n","\n","    return result"]},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,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)"],"metadata":{"id":"tp3Y2tN7FeUb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZTkJaz0GLG5T"},"outputs":[],"source":["#8-20\n","#性能評価\n","pprint.pprint(evaluate_model(entities_list, entities_predicted_list), indent=3, sort_dicts=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"duBQSejb_Tgy"},"outputs":[],"source":["# 抽出データ比較用CSV生成\n","import pandas as pd\n","n = 0\n","list_for_df = []\n","for predictions, corrections, sample in zip(entities_predicted_list, entities_list, dataset_test):\n","  n += 1\n","  s_name = sample['text']\n","  p_lst = []\n","  c_lst = []\n","  for p in predictions:\n","    p_lst.append(p['name'])\n","  for c in corrections:\n","    c_lst.append(c['name'])\n","  while len(c_lst) != len(p_lst):\n","    if len(c_lst) > len(p_lst):\n","      p_lst.append(\"[hoge]\")\n","    else:\n","      c_lst.append(\"[hoge]\")\n","  i = 0\n","  for c_token, p_token in zip(c_lst, p_lst):\n","    dict_for_df = {}\n","    i += 1\n","    t_name = \"token\" + str(i)\n","    dict_for_df['sentence'] = s_name\n","    dict_for_df['token'] = t_name\n","    dict_for_df['correct'] = c_token\n","    dict_for_df['predicted'] = p_token\n","    list_for_df.append(dict_for_df)\n","df = pd.DataFrame(list_for_df)\n","df.to_csv(\"result.csv\", index=None, encoding=\"shift-jis\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"14WwUXs2QqeA3qEChai-dxK7hSOHohwSv","timestamp":1684750913180}],"authorship_tag":"ABX9TyME/Vbd8XjEnAejjOR0l+1I"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}