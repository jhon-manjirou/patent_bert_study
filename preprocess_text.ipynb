{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOtCLPJjeeHBJ7U1LCba1X2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!python --version"],"metadata":{"id":"eKYHKAY1XhJ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import glob\n","import json\n","import unicodedata\n","import pandas as pd"],"metadata":{"id":"RbFvGL_VMzIS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# txt -> csv\n","file_list = glob.glob(\"*.txt\")\n","row_data = []\n","\n","for file in file_list:\n","  file_name = \"text_list_csv/\" + file[:13] + \".csv\"\n","  with open(file)as f:\n","    text = f.read()\n","    text = text.replace('\\n', '').replace(' ', '')\n","    text = re.sub('【\\d{4}】', '', text)\n","  # text = \"(１２３４)から（１）、（２）を抽出\"\n","\n","  c1 = \"\"\n","  c2 = \"\"\n","  text = unicodedata.normalize('NFKC', text).replace('\\u309a', '').replace('\\u2014', '')\n","  if re.search('(?<=【発明を実施するための形態】)(.*?)(?=【\\w+】)', text):\n","    c1 = re.search('(?<=【発明を実施するための形態】)(.*?)(?=【\\w+】)', text).group()\n","  if re.search('(?<=【実施例】)(.*?)(?=【\\w+】)', text):\n","    c2 = re.search('(?<=【実施例】)(.*?)(?=【\\w+】)', text).group()\n","  text = c1 + c2\n","  b_text =  [x + '\\n\\n' for x in text[0::1200]]\n","  with open('sample999.txt', 'w', encoding='shift-jis')as f:\n","    f.write(text)\n","  sentence_list = []\n","  for s in text.split('。'):\n","    if len(s) > 256:\n","      for pos in range(0, len(s), 256):\n","        sentence_list.append(s[pos:pos + 256])\n","    else:\n","      sentence_list.append(s)\n","  dic_for_df = {}\n","  dic_for_df['text'] = sentence_list\n","  df = pd.DataFrame(dic_for_df)\n","  df.to_csv(file_name, index=False, encoding='shift-jis')"],"metadata":{"id":"Pz67pwYOET1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# csv結合\n","file_lst = glob.glob('path/to/*.csv')\n","data_lst = []\n","for file in file_lst:\n","  data_lst.append(pd.read_csv(file, encoding='shift-jis', header=None).drop(0))\n","df = pd.concat(data_lst, axis=0, sort=True)\n","csv_name = 'hsec_total_uq.csv'\n","df.to_csv(csv_name, encoding='shift-jis', index=None, header=None)"],"metadata":{"id":"Ta1Vylw967q-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file = pd.read_csv(csv_name, encoding='shift-jis', header=None)\n","dict_lst = []\n","for col in file.values:\n","  d = {}\n","  text = col[0]\n","  d['text'] = text\n","  wordlist = []\n","  for w in col[1:]:\n","    if not pd.isna(w):\n","      wordlist.append(w)\n","\n","  elist = []\n","  for e in wordlist:\n","    worddict = {}\n","    worddict['name'] = e\n","    end_pos = text.find(e) + len(e)\n","    worddict['span'] = [text.find(e), end_pos]\n","    id = \"技術語\"\n","    worddict['type'] = id\n","    elist.append(worddict)\n","  d['entities'] = elist\n","  dict_lst.append(d)\n","print(dict_lst)\n","\n","with open('json_name.json', 'w') as f:\n","  json.dump(dict_lst, f, indent=2, ensure_ascii=False)"],"metadata":{"id":"ooHGlLzq3I-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 文字位置の観測\n","# 部分一致語、同一単語による位置の重複を避けるため、文字列の検索位置を適宜更新する。\n","# プログラムの仕様上、位置情報を知りたい語句がリスト内に出現順に並んでいる必要がある。\n","dataset = []\n","uq_words = ['偏光子保護フィルム', 'ポリエステルフィルム', 'フィルム']  #　テキスト内の固有表現\n","\n","sample = {}\n","text = \"本発明の偏光子保護フィルムは、ポリエステルフィルムであり、フィルムの流れ方向又は幅方向に対する熱収縮率が最大となる方向の傾きの絶対値が15度以下であることが好ましい\" #サンプルのテキスト\n","sample['text'] = text\n","\n","e_item = [] #entitiesに収容される要素のひとまとまり\n","next_search_spos = 0\n","for entity in uq_words:\n","  e_info = {}\n","  e_info['name'] = entity\n","  end_pos = len(text[:next_search_spos]) + text[next_search_spos:].find(entity) + len(entity)\n","  e_info['span'] = [len(text[:next_search_spos]) + text[next_search_spos:].find(entity), end_pos]\n","  id = '技術語'\n","  e_info['type'] = id\n","  e_item.append(e_info)\n","  next_search_spos = end_pos\n","sample['entities'] = e_item\n","dataset.append(sample)\n","\n","print(text[4:13])\n","print(dataset)"],"metadata":{"id":"FBlcDGWvwBFP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_list = [\"カモシカ\", \"シカ\", \"アシカ\"]\n","text = \"カモシカもシカも確かに鹿だが、アシカは確か鹿ではない\"\n","\n","#変数を用意して繰り返しの都度、検索する範囲を変更する\n","next_search_spos = 0\n","for word in word_list:\n","  start_pos = len(text[:next_search_spos]) + text[next_search_spos:].find(word) # 開始位置\n","  end_pos =  len(text[:next_search_spos]) + text[next_search_spos:].find(word) + len(word) # 終了位置\n","  print(word, start_pos, end_pos) # (リスト要素, 開始位置, 終了位置)\n","  next_search_spos = end_pos"],"metadata":{"id":"U18ppgWCNlte"},"execution_count":null,"outputs":[]}]}